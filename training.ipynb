{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Squat quality scoring with TensorFlow\n",
    "\n",
    "This notebook trains a small BlazePose + LSTM regressor on your local squat videos and predicts a quality score per clip.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-notes",
   "metadata": {},
   "source": [
    "## 1) Environment setup\n",
    "- Installs TensorFlow + MediaPipe + OpenCV.\n",
    "- Use your own data/squats_train and data/squats_test folders; no downloads required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install \"tensorflow<2.17\" tensorflow-io jupyter\n",
    "!python -m pip install mediapipe opencv-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-config",
   "metadata": {},
   "source": [
    "## 2) Imports and configuration\n",
    "- Adjust paths or scoring scale if needed.\n",
    "- Scores are expected in data/squat_scores.csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "NUM_FRAMES = 16\n",
    "IMG_SIZE = 160\n",
    "NUM_LANDMARKS = 33  # BlazePose outputs 33 landmarks\n",
    "LANDMARK_DIMS = 4   # x, y, z, visibility\n",
    "SCORE_SCALE = 100.0  # labels are 0-100; model trains on 0-1 internally\n",
    "\n",
    "DATA_ROOT = Path(\"data\")\n",
    "TRAIN_DIR = DATA_ROOT / \"squats_train\"\n",
    "TEST_DIR = DATA_ROOT / \"squats_test\"\n",
    "LABELS_PATH = DATA_ROOT / \"squat_scores.csv\"\n",
    "MODEL_DIR = Path(\"checkpoints\")\n",
    "\n",
    "VIDEO_EXTS = (\".mp4\", \".mov\", \".avi\", \".mkv\")\n",
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TRAIN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "TEST_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(tf.__version__)\n",
    "print(\"Data root:\", DATA_ROOT.resolve())\n",
    "print(\"Model dir:\", MODEL_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download",
   "metadata": {},
   "source": [
    "## 3) Prepare local data and labels\n",
    "- A CSV template is generated listing every video under data/squats_train and data/squats_test.\n",
    "- Fill in the score column (0-100). At least two labeled train videos are required to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_videos(root: Path):\n",
    "    return sorted(\n",
    "        p for p in root.rglob(\"*\")\n",
    "        if p.suffix.lower() in VIDEO_EXTS and p.is_file()\n",
    "    )\n",
    "\n",
    "\n",
    "def ensure_label_file():\n",
    "    existing = {}\n",
    "    if LABELS_PATH.exists():\n",
    "        with LABELS_PATH.open(\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                existing[row.get(\"relative_path\", \"\")] = row.get(\"score\", \"\")\n",
    "\n",
    "    rows = []\n",
    "    for p in list_videos(TRAIN_DIR) + list_videos(TEST_DIR):\n",
    "        rel = p.relative_to(DATA_ROOT).as_posix()\n",
    "        rows.append({\"relative_path\": rel, \"score\": existing.get(rel, \"\")})\n",
    "\n",
    "    LABELS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with LABELS_PATH.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"relative_path\", \"score\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"Label file ready at {LABELS_PATH}. Fill in 'score' (0-{int(SCORE_SCALE)}) for each row.\")\n",
    "    return rows\n",
    "\n",
    "\n",
    "_ = ensure_label_file()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summaries",
   "metadata": {},
   "source": [
    "### Label summary / sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labeled_samples():\n",
    "    samples = []\n",
    "    missing = []\n",
    "    with LABELS_PATH.open(\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            rel = row.get(\"relative_path\", \"\")\n",
    "            score_str = row.get(\"score\", \"\").strip()\n",
    "            if not rel:\n",
    "                continue\n",
    "\n",
    "            full = DATA_ROOT / rel\n",
    "            if not full.exists():\n",
    "                missing.append(rel)\n",
    "                continue\n",
    "\n",
    "            if not score_str:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                score = float(score_str)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping {rel}: invalid score '{score_str}'\")\n",
    "                continue\n",
    "\n",
    "            score = max(0.0, min(SCORE_SCALE, score))\n",
    "            samples.append((str(full), score))\n",
    "\n",
    "    if missing:\n",
    "        print(\"Warning: paths not found on disk:\", missing)\n",
    "\n",
    "    print(f\"Loaded {len(samples)} labeled samples.\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "labeled_samples = load_labeled_samples()\n",
    "if len(labeled_samples) < 2:\n",
    "    raise ValueError(\"Add scores in the CSV (at least 2 labeled videos) before training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tfdata",
   "metadata": {},
   "source": [
    "## 4) Build a TensorFlow input pipeline\n",
    "- Uniformly sample frames, run BlazePose to get 33 landmarks per frame, normalize, and emit flattened keypoints.\n",
    "- Labels are normalized to 0-1 during training; final scores are rescaled to 0-100.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "pose_detector = mp_pose.Pose(\n",
    "    static_image_mode=False,\n",
    "    model_complexity=1,\n",
    "    enable_segmentation=False,\n",
    "    smooth_landmarks=True,\n",
    ")\n",
    "\n",
    "\n",
    "def _sample_frame_indices(total_frames: int, num_target: int) -> np.ndarray:\n",
    "    if total_frames <= 0:\n",
    "        return np.zeros((num_target,), dtype=np.int32)\n",
    "    idxs = np.linspace(0, max(total_frames - 1, 0), num_target).astype(np.int32)\n",
    "    return idxs\n",
    "\n",
    "\n",
    "def _normalize_landmarks(landmarks: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Center on hips, scale by torso/hip distance, rotate so hips are horizontal.\"\"\"\n",
    "    left_hip, right_hip = landmarks[23, :3], landmarks[24, :3]\n",
    "    left_shoulder, right_shoulder = landmarks[11, :3], landmarks[12, :3]\n",
    "\n",
    "    center_hip = (left_hip + right_hip) / 2.0\n",
    "    center_shoulder = (left_shoulder + right_shoulder) / 2.0\n",
    "    torso = np.linalg.norm(center_shoulder[:2] - center_hip[:2])\n",
    "    hip_dist = np.linalg.norm(left_hip[:2] - right_hip[:2])\n",
    "    scale = max(torso, hip_dist, 1e-3)\n",
    "\n",
    "    landmarks[:, :3] = (landmarks[:, :3] - center_hip) / scale\n",
    "\n",
    "    hip_vec = right_hip[:2] - left_hip[:2]\n",
    "    angle = np.arctan2(hip_vec[1], hip_vec[0] + 1e-6)\n",
    "    cos_a, sin_a = np.cos(-angle), np.sin(-angle)\n",
    "    rot = np.array([[cos_a, -sin_a], [sin_a, cos_a]], dtype=np.float32)\n",
    "    landmarks[:, :2] = landmarks[:, :2] @ rot.T\n",
    "    return landmarks\n",
    "\n",
    "\n",
    "def _extract_keypoints_np(video_path: str) -> np.ndarray:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    num_frames = len(frames)\n",
    "    keypoints = np.zeros((NUM_FRAMES, NUM_LANDMARKS, LANDMARK_DIMS), dtype=np.float32)\n",
    "    if num_frames == 0:\n",
    "        return keypoints\n",
    "\n",
    "    idxs = _sample_frame_indices(num_frames, NUM_FRAMES)\n",
    "    for out_i, frame_idx in enumerate(idxs):\n",
    "        frame = frames[int(frame_idx)]\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose_detector.process(image_rgb)\n",
    "        if results.pose_landmarks:\n",
    "            lm = results.pose_landmarks.landmark\n",
    "            coords = np.array([[p.x, p.y, p.z, p.visibility] for p in lm], dtype=np.float32)\n",
    "            coords = _normalize_landmarks(coords)\n",
    "            keypoints[out_i] = coords\n",
    "    return keypoints\n",
    "\n",
    "\n",
    "def load_keypoints(path: tf.Tensor) -> tf.Tensor:\n",
    "    def _py_decode(p):\n",
    "        return _extract_keypoints_np(p.numpy().decode(\"utf-8\"))\n",
    "\n",
    "    kpts = tf.py_function(_py_decode, [path], tf.float32)\n",
    "    kpts.set_shape((NUM_FRAMES, NUM_LANDMARKS, LANDMARK_DIMS))\n",
    "    return kpts\n",
    "\n",
    "\n",
    "def preprocess(path: tf.Tensor, score: tf.Tensor) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    keypoints = load_keypoints(path)\n",
    "    keypoints = tf.reshape(keypoints, (NUM_FRAMES, NUM_LANDMARKS * LANDMARK_DIMS))\n",
    "    score = tf.cast(score, tf.float32) / SCORE_SCALE\n",
    "    score = tf.expand_dims(score, axis=-1)\n",
    "    return keypoints, score\n",
    "\n",
    "\n",
    "def build_tf_dataset(samples, training: bool):\n",
    "    paths, scores = zip(*samples)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((list(paths), list(scores)))\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=len(paths), seed=SEED, reshuffle_each_iteration=True)\n",
    "    ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def _in_dir(path_str: str, root: Path) -> bool:\n",
    "    try:\n",
    "        Path(path_str).resolve().relative_to(root.resolve())\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "train_samples = [s for s in labeled_samples if _in_dir(s[0], TRAIN_DIR)]\n",
    "test_samples = [s for s in labeled_samples if _in_dir(s[0], TEST_DIR)]\n",
    "if len(train_samples) < 2:\n",
    "    raise ValueError(\"Need at least 2 labeled train videos in squats_train for a train/val split.\")\n",
    "\n",
    "random.shuffle(train_samples)\n",
    "split = max(1, int(0.8 * len(train_samples)))\n",
    "if split >= len(train_samples):\n",
    "    split = len(train_samples) - 1\n",
    "\n",
    "train_ds = build_tf_dataset(train_samples[:split], training=True)\n",
    "val_ds = build_tf_dataset(train_samples[split:], training=False)\n",
    "test_ds = build_tf_dataset(test_samples, training=False) if test_samples else None\n",
    "\n",
    "print(\"Train batches:\", len(train_ds))\n",
    "print(\"Val batches:\", len(val_ds))\n",
    "print(\"Test batches:\", len(test_ds) if test_ds is not None else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model",
   "metadata": {},
   "source": [
    "## 5) Define a lightweight regression model\n",
    "- BiLSTM + pooling over landmark sequences; single sigmoid output predicts normalized score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() -> tf.keras.Model:\n",
    "    inputs = tf.keras.Input(shape=(NUM_FRAMES, NUM_LANDMARKS * LANDMARK_DIMS))\n",
    "    x = tf.keras.layers.Masking(mask_value=0.0)(inputs)\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)  # normalized score 0-1\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"mse\",\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train",
   "metadata": {},
   "source": [
    "## 6) Train\n",
    "- Early stopping on validation MAE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True, monitor=\"val_mae\"),\n",
    "    tf.keras.callbacks.ModelCheckpoint(str(MODEL_DIR / \"model.keras\"), save_best_only=True, monitor=\"val_mae\"),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "best_val_mae = min(history.history[\"val_mae\"])\n",
    "print(\"Best val MAE (normalized 0-1):\", best_val_mae)\n",
    "print(\"Best val MAE (score units):\", best_val_mae * SCORE_SCALE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate",
   "metadata": {},
   "source": [
    "## 7) Evaluate and save artifacts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_target = test_ds if test_ds is not None else val_ds\n",
    "eval_results = model.evaluate(eval_target, return_dict=True)\n",
    "print(eval_results)\n",
    "print(f\"MAE in score units: {eval_results['mae'] * SCORE_SCALE:.2f}\")\n",
    "\n",
    "export_dir = MODEL_DIR / \"squat_scorer.keras\"\n",
    "model.save(export_dir)\n",
    "with (MODEL_DIR / \"score_scale.txt\").open(\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(SCORE_SCALE))\n",
    "\n",
    "print(\"Artifacts saved to\", MODEL_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c66451",
   "metadata": {},
   "source": [
    "## 8) Export TFLite for Android\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fbbe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_DIR = Path(\"checkpoints\")\n",
    "saved_model_dir = MODEL_DIR / \"squat_scorer_savedmodel\"  # or wherever you exported\n",
    "tflite_path = MODEL_DIR / \"squat_scorer.tflite\"\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(str(saved_model_dir))\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# Key flags for TensorList + LSTM\n",
    "converter.experimental_enable_resource_variables = True\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,\n",
    "]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "tflite_path.write_bytes(tflite_model)\n",
    "print(\"Wrote\", tflite_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference",
   "metadata": {},
   "source": [
    "## 9) Single-sample inference helper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infer-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sample(video_path: str):\n",
    "    keypoints = _extract_keypoints_np(video_path)\n",
    "    keypoints = keypoints.reshape(1, NUM_FRAMES, NUM_LANDMARKS * LANDMARK_DIMS)\n",
    "    score_norm = float(model.predict(keypoints, verbose=0)[0][0])\n",
    "    return score_norm * SCORE_SCALE\n",
    "\n",
    "\n",
    "example_path = train_samples[0][0] if train_samples else labeled_samples[0][0]\n",
    "pred_score = predict_sample(example_path)\n",
    "print(f\"Predicted score: {pred_score:.2f} (0-{int(SCORE_SCALE)}) on {example_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
